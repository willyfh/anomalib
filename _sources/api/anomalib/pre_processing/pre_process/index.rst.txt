:py:mod:`anomalib.pre_processing.pre_process`
=============================================

.. py:module:: anomalib.pre_processing.pre_process

.. autoapi-nested-parse::

   Pre Process.

   This module contains `PreProcessor` class that applies preprocessing
   to an input image before the forward-pass stage.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   anomalib.pre_processing.pre_process.PreProcessor




.. py:class:: PreProcessor(config: Optional[Union[str, albumentations.Compose]] = None, image_size: Optional[Union[int, Tuple]] = None, to_tensor: bool = True)

   Applies pre-processing and data augmentations to the input and returns the transformed output.

   Output could be either numpy ndarray or torch tensor.
   When `PreProcessor` class is used for training, the output would be `torch.Tensor`.
   For the inference it returns a numpy array.

   :param config: Transformation configurations.
                  When it is ``None``, ``PreProcessor`` only applies resizing. When it is ``str``
                  it loads the config via ``albumentations`` deserialisation methos . Defaults to None.
   :type config: Optional[Union[str, A.Compose]], optional
   :param image_size: When there is no config,
   :type image_size: Optional[Union[int, Tuple[int, int]]], optional
   :param ``image_size`` resizes the image. Defaults to None.:
   :param to_tensor: Boolean to check whether the augmented image is transformed
                     into a tensor or not. Defaults to True.
   :type to_tensor: bool, optional

   .. rubric:: Examples

   >>> import skimage
   >>> image = skimage.data.astronaut()

   >>> pre_processor = PreProcessor(image_size=256, to_tensor=False)
   >>> output = pre_processor(image=image)
   >>> output["image"].shape
   (256, 256, 3)

   >>> pre_processor = PreProcessor(image_size=256, to_tensor=True)
   >>> output = pre_processor(image=image)
   >>> output["image"].shape
   torch.Size([3, 256, 256])


   Transforms could be read from albumentations Compose object.
       >>> import albumentations as A
       >>> from albumentations.pytorch import ToTensorV2
       >>> config = A.Compose([A.Resize(512, 512), ToTensorV2()])
       >>> pre_processor = PreProcessor(config=config, to_tensor=False)
       >>> output = pre_processor(image=image)
       >>> output["image"].shape
       (512, 512, 3)
       >>> type(output["image"])
       numpy.ndarray

   Transforms could be deserialized from a yaml file.
       >>> transforms = A.Compose([A.Resize(1024, 1024), ToTensorV2()])
       >>> A.save(transforms, "/tmp/transforms.yaml", data_format="yaml")
       >>> pre_processor = PreProcessor(config="/tmp/transforms.yaml")
       >>> output = pre_processor(image=image)
       >>> output["image"].shape
       torch.Size([3, 1024, 1024])

   .. py:method:: get_transforms(self) -> albumentations.Compose

      Get transforms from config or image size.

      :returns:

                List of albumentation transformations to apply to the
                    input image.
      :rtype: A.Compose


   .. py:method:: __call__(self, *args, **kwargs)

      Return transformed arguments.


   .. py:method:: _get_height_and_width(self) -> Tuple[Optional[int], Optional[int]]

      Extract height and width from image size attribute.



