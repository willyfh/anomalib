:py:mod:`anomalib.utils.metrics`
================================

.. py:module:: anomalib.utils.metrics

.. autoapi-nested-parse::

   Custom anomaly evaluation metrics.



Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   adaptive_threshold/index.rst
   anomaly_score_distribution/index.rst
   auroc/index.rst
   collection/index.rst
   min_max/index.rst
   optimal_f1/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   anomalib.utils.metrics.AdaptiveThreshold
   anomalib.utils.metrics.AnomalyScoreDistribution
   anomalib.utils.metrics.AUROC
   anomalib.utils.metrics.MinMax
   anomalib.utils.metrics.OptimalF1




.. py:class:: AdaptiveThreshold(default_value: float = 0.5, **kwargs)

   Bases: :py:obj:`torchmetrics.Metric`

   Optimal F1 Metric.

   Compute the optimal F1 score at the adaptive threshold, based on the F1 metric of the true labels and the
   predicted anomaly scores.

   .. py:method:: update(self, preds: torch.Tensor, target: torch.Tensor) -> None

      Update the precision-recall curve metric.


   .. py:method:: compute(self) -> torch.Tensor

      Compute the threshold that yields the optimal F1 score.

      Compute the F1 scores while varying the threshold. Store the optimal
      threshold as attribute and return the maximum value of the F1 score.

      :returns: Value of the F1 score at the optimal threshold.



.. py:class:: AnomalyScoreDistribution(**kwargs)

   Bases: :py:obj:`torchmetrics.Metric`

   Mean and standard deviation of the anomaly scores of normal training data.

   .. py:method:: update(self, anomaly_scores: Optional[torch.Tensor] = None, anomaly_maps: Optional[torch.Tensor] = None) -> None

      Update the precision-recall curve metric.


   .. py:method:: compute(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]

      Compute stats.



.. py:class:: AUROC(num_classes: Optional[int] = None, pos_label: Optional[int] = None, compute_on_step: Optional[bool] = None, **kwargs: Dict[str, Any])

   Bases: :py:obj:`torchmetrics.ROC`

   Area under the ROC curve.

   .. py:method:: compute(self) -> torch.Tensor

      First compute ROC curve, then compute area under the curve.

      :returns: Value of the AUROC metric



.. py:class:: MinMax(**kwargs)

   Bases: :py:obj:`torchmetrics.Metric`

   Track the min and max values of the observations in each batch.

   .. py:method:: update(self, predictions: torch.Tensor) -> None

      Update the min and max values.


   .. py:method:: compute(self) -> Tuple[torch.Tensor, torch.Tensor]

      Return min and max values.



.. py:class:: OptimalF1(num_classes: int, **kwargs)

   Bases: :py:obj:`torchmetrics.Metric`

   Optimal F1 Metric.

   Compute the optimal F1 score at the adaptive threshold, based on the F1 metric of the true labels and the
   predicted anomaly scores.

   .. py:method:: update(self, preds: torch.Tensor, target: torch.Tensor) -> None

      Update the precision-recall curve metric.


   .. py:method:: compute(self) -> torch.Tensor

      Compute the value of the optimal F1 score.

      Compute the F1 scores while varying the threshold. Store the optimal
      threshold as attribute and return the maximum value of the F1 score.

      :returns: Value of the F1 score at the optimal threshold.



