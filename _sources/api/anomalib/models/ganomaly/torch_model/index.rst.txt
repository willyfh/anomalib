:py:mod:`anomalib.models.ganomaly.torch_model`
==============================================

.. py:module:: anomalib.models.ganomaly.torch_model

.. autoapi-nested-parse::

   Torch models defining encoder, decoder, Generator and Discriminator.

   Code adapted from https://github.com/samet-akcay/ganomaly.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   anomalib.models.ganomaly.torch_model.Encoder
   anomalib.models.ganomaly.torch_model.Decoder
   anomalib.models.ganomaly.torch_model.Discriminator
   anomalib.models.ganomaly.torch_model.Generator
   anomalib.models.ganomaly.torch_model.GanomalyModel




.. py:class:: Encoder(input_size: Tuple[int, int], latent_vec_size: int, num_input_channels: int, n_features: int, extra_layers: int = 0, add_final_conv_layer: bool = True)

   Bases: :py:obj:`torch.nn.Module`

   Encoder Network.

   :param input_size: Size of input image
   :type input_size: Tuple[int, int]
   :param latent_vec_size: Size of latent vector z
   :type latent_vec_size: int
   :param num_input_channels: Number of input channels in the image
   :type num_input_channels: int
   :param n_features: Number of features per convolution layer
   :type n_features: int
   :param extra_layers: Number of extra layers since the network uses only a single encoder layer by default.
                        Defaults to 0.
   :type extra_layers: int

   .. py:method:: forward(self, input_tensor: torch.Tensor)

      Return latent vectors.



.. py:class:: Decoder(input_size: Tuple[int, int], latent_vec_size: int, num_input_channels: int, n_features: int, extra_layers: int = 0)

   Bases: :py:obj:`torch.nn.Module`

   Decoder Network.

   :param input_size: Size of input image
   :type input_size: Tuple[int, int]
   :param latent_vec_size: Size of latent vector z
   :type latent_vec_size: int
   :param num_input_channels: Number of input channels in the image
   :type num_input_channels: int
   :param n_features: Number of features per convolution layer
   :type n_features: int
   :param extra_layers: Number of extra layers since the network uses only a single encoder layer by default.
                        Defaults to 0.
   :type extra_layers: int

   .. py:method:: forward(self, input_tensor)

      Return generated image.



.. py:class:: Discriminator(input_size: Tuple[int, int], num_input_channels: int, n_features: int, extra_layers: int = 0)

   Bases: :py:obj:`torch.nn.Module`

   Discriminator.

       Made of only one encoder layer which takes x and x_hat to produce a score.

   :param input_size: Input image size.
   :type input_size: Tuple[int,int]
   :param num_input_channels: Number of image channels.
   :type num_input_channels: int
   :param n_features: Number of feature maps in each convolution layer.
   :type n_features: int
   :param extra_layers: Add extra intermediate layers. Defaults to 0.
   :type extra_layers: int, optional

   .. py:method:: forward(self, input_tensor)

      Return class of object and features.



.. py:class:: Generator(input_size: Tuple[int, int], latent_vec_size: int, num_input_channels: int, n_features: int, extra_layers: int = 0, add_final_conv_layer: bool = True)

   Bases: :py:obj:`torch.nn.Module`

   Generator model.

   Made of an encoder-decoder-encoder architecture.

   :param input_size: Size of input data.
   :type input_size: Tuple[int,int]
   :param latent_vec_size: Dimension of latent vector produced between the first encoder-decoder.
   :type latent_vec_size: int
   :param num_input_channels: Number of channels in input image.
   :type num_input_channels: int
   :param n_features: Number of feature maps in each convolution layer.
   :type n_features: int
   :param extra_layers: Extra intermediate layers in the encoder/decoder. Defaults to 0.
   :type extra_layers: int, optional
   :param add_final_conv_layer: Add a final convolution layer in the decoder. Defaults to True.
   :type add_final_conv_layer: bool, optional

   .. py:method:: forward(self, input_tensor)

      Return generated image and the latent vectors.



.. py:class:: GanomalyModel(input_size: Tuple[int, int], num_input_channels: int, n_features: int, latent_vec_size: int, extra_layers: int = 0, add_final_conv_layer: bool = True, wadv: int = 1, wcon: int = 50, wenc: int = 1)

   Bases: :py:obj:`torch.nn.Module`

   Ganomaly Model.

   :param input_size: Input dimension.
   :type input_size: Tuple[int,int]
   :param num_input_channels: Number of input channels.
   :type num_input_channels: int
   :param n_features: Number of features layers in the CNNs.
   :type n_features: int
   :param latent_vec_size: Size of autoencoder latent vector.
   :type latent_vec_size: int
   :param extra_layers: Number of extra layers for encoder/decoder. Defaults to 0.
   :type extra_layers: int, optional
   :param add_final_conv_layer: Add convolution layer at the end. Defaults to True.
   :type add_final_conv_layer: bool, optional
   :param wadv: Weight for adversarial loss. Defaults to 1.
   :type wadv: int, optional
   :param wcon: Image regeneration weight. Defaults to 50.
   :type wcon: int, optional
   :param wenc: Latent vector encoder weight. Defaults to 1.
   :type wenc: int, optional

   .. py:method:: weights_init(module: torch.nn.Module)
      :staticmethod:

      Initialize DCGAN weights.

      :param module: [description]
      :type module: nn.Module


   .. py:method:: get_discriminator_loss(self, images: torch.Tensor) -> torch.Tensor

      Calculates loss for discriminator.

      :param images: Input images.
      :type images: Tensor

      :returns: Discriminator loss.
      :rtype: Tensor


   .. py:method:: get_generator_loss(self, images: torch.Tensor) -> torch.Tensor

      Calculates loss for generator.

      :param images: Input images.
      :type images: Tensor

      :returns: Generator loss.
      :rtype: Tensor


   .. py:method:: forward(self, batch: torch.Tensor) -> torch.Tensor

      Get scores for batch.

      :param batch: Images
      :type batch: Tensor

      :returns: Regeneration scores.
      :rtype: Tensor



