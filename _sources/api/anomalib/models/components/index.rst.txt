:py:mod:`anomalib.models.components`
====================================

.. py:module:: anomalib.models.components

.. autoapi-nested-parse::

   Components used within the models.



Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   base/index.rst
   dimensionality_reduction/index.rst
   feature_extractors/index.rst
   filters/index.rst
   freia/index.rst
   layers/index.rst
   sampling/index.rst
   stats/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   anomalib.models.components.AnomalyModule
   anomalib.models.components.DynamicBufferModule
   anomalib.models.components.PCA
   anomalib.models.components.SparseRandomProjection
   anomalib.models.components.FeatureExtractor
   anomalib.models.components.GaussianBlur2d
   anomalib.models.components.KCenterGreedy
   anomalib.models.components.GaussianKDE
   anomalib.models.components.MultiVariateGaussian




.. py:class:: AnomalyModule

   Bases: :py:obj:`pytorch_lightning.LightningModule`, :py:obj:`abc.ABC`

   AnomalyModule to train, validate, predict and test images.

   Acts as a base class for all the Anomaly Modules in the library.

   .. py:method:: forward(self, batch)

      Forward-pass input tensor to the module.

      :param batch: Input Tensor
      :type batch: Tensor

      :returns: Output tensor from the model.
      :rtype: Tensor


   .. py:method:: validation_step(self, batch, batch_idx) -> dict
      :abstractmethod:

      To be implemented in the subclasses.


   .. py:method:: predict_step(self, batch: Any, batch_idx: int, _dataloader_idx: Optional[int] = None) -> Any

      Step function called during :meth:`~pytorch_lightning.trainer.trainer.Trainer.predict`.

      By default, it calls :meth:`~pytorch_lightning.core.lightning.LightningModule.forward`.
      Override to add any processing logic.

      :param batch: Current batch
      :type batch: Tensor
      :param batch_idx: Index of current batch
      :type batch_idx: int
      :param _dataloader_idx: Index of the current dataloader
      :type _dataloader_idx: int

      :returns: Predicted output


   .. py:method:: test_step(self, batch, _)

      Calls validation_step for anomaly map/score calculation.

      :param batch: Input batch
      :type batch: Tensor
      :param _: Index of the batch.

      :returns: Dictionary containing images, features, true labels and masks.
                These are required in `validation_epoch_end` for feature concatenation.


   .. py:method:: validation_step_end(self, val_step_outputs)

      Called at the end of each validation step.


   .. py:method:: test_step_end(self, test_step_outputs)

      Called at the end of each test step.


   .. py:method:: validation_epoch_end(self, outputs)

      Compute threshold and performance metrics.

      :param outputs: Batch of outputs from the validation step


   .. py:method:: test_epoch_end(self, outputs)

      Compute and save anomaly scores of the test set.

      :param outputs: Batch of outputs from the validation step


   .. py:method:: _compute_adaptive_threshold(self, outputs)


   .. py:method:: _collect_outputs(image_metric, pixel_metric, outputs)
      :staticmethod:


   .. py:method:: _post_process(outputs)
      :staticmethod:

      Compute labels based on model predictions.


   .. py:method:: _outputs_to_cpu(output)
      :staticmethod:


   .. py:method:: _log_metrics(self)

      Log computed performance metrics.



.. py:class:: DynamicBufferModule

   Bases: :py:obj:`abc.ABC`, :py:obj:`torch.nn.Module`

   Torch module that allows loading variables from the state dict even in the case of shape mismatch.

   .. py:method:: get_tensor_attribute(self, attribute_name: str) -> torch.Tensor

      Get attribute of the tensor given the name.

      :param attribute_name: Name of the tensor
      :type attribute_name: str

      :raises ValueError: `attribute_name` is not a torch Tensor

      :returns: Tensor attribute
      :rtype: Tensor


   .. py:method:: _load_from_state_dict(self, state_dict: dict, prefix: str, *args)

      Resizes the local buffers to match those stored in the state dict.

      Overrides method from parent class.

      :param state_dict: State dictionary containing weights
      :type state_dict: dict
      :param prefix: Prefix of the weight file.
      :type prefix: str
      :param \*args:



.. py:class:: PCA(n_components: Union[float, int])

   Bases: :py:obj:`anomalib.models.components.base.DynamicBufferModule`

   Principle Component Analysis (PCA).

   :param n_components: Number of components. Can be either integer number of components
                        or a ratio between 0-1.
   :type n_components: float

   .. py:method:: fit(self, dataset: torch.Tensor) -> None

      Fits the PCA model to the dataset.

      :param dataset: Input dataset to fit the model.
      :type dataset: Tensor


   .. py:method:: fit_transform(self, dataset: torch.Tensor) -> torch.Tensor

      Fit and transform PCA to dataset.

      :param dataset: Dataset to which the PCA if fit and transformed
      :type dataset: Tensor

      :returns: Transformed dataset


   .. py:method:: transform(self, features: torch.Tensor) -> torch.Tensor

      Transforms the features based on singular vectors calculated earlier.

      :param features: Input features
      :type features: Tensor

      :returns: Transformed features


   .. py:method:: inverse_transform(self, features: torch.Tensor) -> torch.Tensor

      Inverses the transformed features.

      :param features: Transformed features
      :type features: Tensor

      Returns: Inverse features


   .. py:method:: forward(self, features: torch.Tensor) -> torch.Tensor

      Transforms the features.

      :param features: Input features
      :type features: Tensor

      :returns: Transformed features



.. py:class:: SparseRandomProjection(eps: float = 0.1, random_state: Optional[int] = None)

   Sparse Random Projection using PyTorch operations.

   :param eps: Minimum distortion rate parameter for calculating
               Johnson-Lindenstrauss minimum dimensions. Defaults to 0.1.
   :type eps: float, optional
   :param random_state: Uses the seed to set the random
                        state for sample_without_replacement function. Defaults to None.
   :type random_state: Optional[int], optional

   .. py:method:: _sparse_random_matrix(self, n_features: int)

      Random sparse matrix. Based on https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf.

      :param n_features: Dimentionality of the original source space
      :type n_features: int

      :returns:

                Sparse matrix of shape (n_components, n_features).
                    The generated Gaussian random matrix is in CSR (compressed sparse row)
                    format.
      :rtype: Tensor


   .. py:method:: johnson_lindenstrauss_min_dim(self, n_samples: int, eps: float = 0.1)

      Find a 'safe' number of components to randomly project to.

      Ref eqn 2.1 https://cseweb.ucsd.edu/~dasgupta/papers/jl.pdf

      :param n_samples: Number of samples used to compute safe components
      :type n_samples: int
      :param eps: Minimum distortion rate. Defaults to 0.1.
      :type eps: float, optional


   .. py:method:: fit(self, embedding: torch.Tensor) -> SparseRandomProjection

      Generates sparse matrix from the embedding tensor.

      :param embedding: embedding tensor for generating embedding
      :type embedding: Tensor

      :returns: Return self to be used as
                >>> generator = SparseRandomProjection()
                >>> generator = generator.fit()
      :rtype: (SparseRandomProjection)


   .. py:method:: transform(self, embedding: torch.Tensor) -> torch.Tensor

      Project the data by using matrix product with the random matrix.

      :param embedding: Embedding of shape (n_samples, n_features)
                        The input data to project into a smaller dimensional space
      :type embedding: Tensor

      :returns:

                Sparse matrix of shape
                    (n_samples, n_components) Projected array.
      :rtype: projected_embedding (Tensor)



.. py:class:: FeatureExtractor(backbone: str, layers: List[str], pre_trained: bool = True)

   Bases: :py:obj:`torch.nn.Module`

   Extract features from a CNN.

   :param backbone: The backbone to which the feature extraction hooks are attached.
   :type backbone: nn.Module
   :param layers: List of layer names of the backbone to which the hooks are attached.
   :type layers: Iterable[str]

   .. rubric:: Example

   >>> import torch
   >>> from anomalib.core.model.feature_extractor import FeatureExtractor

   >>> model = FeatureExtractor(model="resnet18", layers=['layer1', 'layer2', 'layer3'])
   >>> input = torch.rand((32, 3, 256, 256))
   >>> features = model(input)

   >>> [layer for layer in features.keys()]
       ['layer1', 'layer2', 'layer3']
   >>> [feature.shape for feature in features.values()]
       [torch.Size([32, 64, 64, 64]), torch.Size([32, 128, 32, 32]), torch.Size([32, 256, 16, 16])]

   .. py:method:: _map_layer_to_idx(self, offset: int = 3) -> List[int]

      Maps set of layer names to indices of model.

      :param offset:
      :type offset: int

      :returns: Feature map extracted from the CNN


   .. py:method:: forward(self, input_tensor: torch.Tensor) -> Dict[str, torch.Tensor]

      Forward-pass input tensor into the CNN.

      :param input_tensor: Input tensor
      :type input_tensor: Tensor

      :returns: Feature map extracted from the CNN



.. py:class:: GaussianBlur2d(kernel_size: Union[Tuple[int, int], int], sigma: Union[Tuple[float, float], float], channels: int, normalize: bool = True, border_type: str = 'reflect', padding: str = 'same')

   Bases: :py:obj:`torch.nn.Module`

   Compute GaussianBlur in 2d.

   Makes use of kornia functions, but most notably the kernel is not computed
   during the forward pass, and does not depend on the input size. As a caveat,
   the number of channels that are expected have to be provided during initialization.

   .. py:method:: forward(self, input_tensor: torch.Tensor) -> torch.Tensor

      Blur the input with the computed Gaussian.

      :param input_tensor: Input tensor to be blurred.
      :type input_tensor: Tensor

      :returns: Blurred output tensor.
      :rtype: Tensor



.. py:class:: KCenterGreedy(embedding: torch.Tensor, sampling_ratio: float)

   Implements k-center-greedy method.

   :param embedding: Embedding vector extracted from a CNN
   :type embedding: Tensor
   :param sampling_ratio: Ratio to choose coreset size from the embedding size.
   :type sampling_ratio: float

   .. rubric:: Example

   >>> embedding.shape
   torch.Size([219520, 1536])
   >>> sampler = KCenterGreedy(embedding=embedding)
   >>> sampled_idxs = sampler.select_coreset_idxs()
   >>> coreset = embedding[sampled_idxs]
   >>> coreset.shape
   torch.Size([219, 1536])

   .. py:method:: reset_distances(self) -> None

      Reset minimum distances.


   .. py:method:: update_distances(self, cluster_centers: List[int]) -> None

      Update min distances given cluster centers.

      :param cluster_centers: indices of cluster centers
      :type cluster_centers: List[int]


   .. py:method:: get_new_idx(self) -> int

      Get index value of a sample.

      Based on minimum distance of the cluster

      :returns: Sample index
      :rtype: int


   .. py:method:: select_coreset_idxs(self, selected_idxs: Optional[List[int]] = None) -> List[int]

      Greedily form a coreset to minimize the maximum distance of a cluster.

      :param selected_idxs: index of samples already selected. Defaults to an empty set.

      :returns: indices of samples selected to minimize distance to cluster centers


   .. py:method:: sample_coreset(self, selected_idxs: Optional[List[int]] = None) -> torch.Tensor

      Select coreset from the embedding.

      :param selected_idxs: index of samples already selected. Defaults to an empty set.

      :returns: Output coreset
      :rtype: Tensor

      .. rubric:: Example

      >>> embedding.shape
      torch.Size([219520, 1536])
      >>> sampler = KCenterGreedy(...)
      >>> coreset = sampler.sample_coreset()
      >>> coreset.shape
      torch.Size([219, 1536])



.. py:class:: GaussianKDE(dataset: Optional[torch.Tensor] = None)

   Bases: :py:obj:`anomalib.models.components.base.DynamicBufferModule`

   Gaussian Kernel Density Estimation.

   :param dataset: Dataset on which to fit the KDE model. Defaults to None.
   :type dataset: Optional[Tensor], optional

   .. py:method:: forward(self, features: torch.Tensor) -> torch.Tensor

      Get the KDE estimates from the feature map.

      :param features: Feature map extracted from the CNN
      :type features: Tensor

      Returns: KDE Estimates


   .. py:method:: fit(self, dataset: torch.Tensor) -> None

      Fit a KDE model to the input dataset.

      :param dataset: Input dataset.
      :type dataset: Tensor

      :returns: None


   .. py:method:: cov(tensor: torch.Tensor) -> torch.Tensor
      :staticmethod:

      Calculate the unbiased covariance matrix.

      :param tensor: Input tensor from which covariance matrix is computed.
      :type tensor: Tensor

      :returns: Output covariance matrix.



.. py:class:: MultiVariateGaussian(n_features, n_patches)

   Bases: :py:obj:`torch.nn.Module`

   Multi Variate Gaussian Distribution.

   .. py:method:: _cov(observations: torch.Tensor, rowvar: bool = False, bias: bool = False, ddof: Optional[int] = None, aweights: torch.Tensor = None) -> torch.Tensor
      :staticmethod:

      Estimates covariance matrix like numpy.cov.

      :param observations: A 1-D or 2-D array containing multiple variables and observations.
                           Each row of `m` represents a variable, and each column a single
                           observation of all those variables. Also see `rowvar` below.
      :type observations: Tensor
      :param rowvar: If `rowvar` is True (default), then each row represents a
                     variable, with observations in the columns. Otherwise, the relationship
                     is transposed: each column represents a variable, while the rows
                     contain observations. Defaults to False.
      :type rowvar: bool
      :param bias: Default normalization (False) is by ``(N - 1)``, where ``N`` is the
                   number of observations given (unbiased estimate). If `bias` is True,
                   then normalization is by ``N``. These values can be overridden by using
                   the keyword ``ddof`` in numpy versions >= 1.5. Defaults to False
      :type bias: bool
      :param ddof: If not ``None`` the default value implied by `bias` is overridden.
                   Note that ``ddof=1`` will return the unbiased estimate, even if both
                   `fweights` and `aweights` are specified, and ``ddof=0`` will return
                   the simple average. See the notes for the details. The default value
                   is ``None``.
      :type ddof: Optional, int
      :param aweights: 1-D array of observation vector weights. These relative weights are
                       typically large for observations considered "important" and smaller for
                       observations considered less "important". If ``ddof=0`` the array of
                       weights can be used to assign probabilities to observation vectors. (Default value = None)
      :type aweights: Tensor

      :returns: The covariance matrix of the variables.


   .. py:method:: forward(self, embedding: torch.Tensor) -> List[torch.Tensor]

      Calculate multivariate Gaussian distribution.

      :param embedding: CNN features whose dimensionality is reduced via either random sampling or PCA.
      :type embedding: Tensor

      :returns: mean and inverse covariance of the multi-variate gaussian distribution that fits the features.


   .. py:method:: fit(self, embedding: torch.Tensor) -> List[torch.Tensor]

      Fit multi-variate gaussian distribution to the input embedding.

      :param embedding: Embedding vector extracted from CNN.
      :type embedding: Tensor

      :returns: Mean and the covariance of the embedding.



